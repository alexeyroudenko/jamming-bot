{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install -U spacy\n",
    "# python -m spacy download en_core_web_lg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy.cli\n",
    "# spacy.cli.download(\"en_core_web_md\")\n",
    "# en_core_web_md\n",
    "# en_core_web_lg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jamming bot is a fantasy about a post-apocalyptic future, when the core functions of the internet and assistant bots are defeated and only one self-replicating bot remains, aimlessly browsing the internet. It is a bot that has no goal, only a path. Currently, spiders, crawlers and bots serve a service purpose. They act as search engines, collect information, automate the infrastructure of the internet. Jamming bot is a fantasy about a post-apocalyptic future, when the core functions of the internet and assistant bots are defeated and only one self-replicating bot remains, aimlessly browsing the internet, perhaps studying the general mood of humanity in the scraps of meaning on the pages of the internet. It is a bot that has no goal, only a path. Jamming Bot is a fascinating and slightly melancholic concept, where the last remaining bot represents the legacy of the digital age. Jamming Bot may symbolize the loneliness and permanence of technology that has transcended control and self-improvement. It is like an observer, dwelling among the fragments of information, trying to catch the residual traces of humanity in the scraps of text, in the ruined pages, perhaps even interpreting them as traces of a long-forgotten society. Its movement across the Internet can be seen as a reflection of human aspirations, searches, and experiences, as it accidentally intersects with different fragments of meaning that were once assembled into a single network.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrases, Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)\n",
    "noun_hrases =  [chunk.text for chunk in doc.noun_chunks]\n",
    "noun_hrases_out = []\n",
    "\n",
    "for i in noun_hrases:\n",
    "    if len(i) > 5:\n",
    "        noun_hrases_out.append(i)\n",
    "        \n",
    "# print(noun_hrases_out)\n",
    "# print(\"-------------\")\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"-------------\")\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "print(\"-------------\")\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jammingbot>is\n",
      "is>is\n",
      "a>fantasy\n",
      "fantasy>is\n",
      "on>fantasy\n",
      "the>theme\n",
      "theme>on\n",
      "of>theme\n",
      "a>future\n",
      "post>future\n",
      "->future\n",
      "apocalyptic>future\n",
      "future>of\n",
      ",>future\n",
      "when>defeated\n",
      "the>functions\n",
      "main>functions\n",
      "functions>defeated\n",
      "of>functions\n",
      "the>Internet\n",
      "Internet>of\n",
      "and>functions\n",
      "assistant>bots\n",
      "bots>defeated\n",
      "will>defeated\n",
      "be>defeated\n",
      "defeated>is\n",
      "and>defeated\n",
      "only>one\n",
      "one>bot\n",
      "self>replicating\n",
      "->replicating\n",
      "replicating>bot\n",
      "bot>remain\n",
      "will>remain\n",
      "remain>defeated\n",
      ",>remain\n",
      "aimlessly>plowing\n",
      "plowing>remain\n",
      "the>Internet\n",
      "Internet>plowing\n",
      ".>is\n",
      "This>is\n",
      "is>is\n",
      "a>bot\n",
      "bot>is\n",
      "that>has\n",
      "has>bot\n",
      "no>goal\n",
      "goal>has\n",
      ",>is\n",
      "but>is\n",
      "only>path\n",
      "a>path\n",
      "path>is\n",
      ".>is\n"
     ]
    }
   ],
   "source": [
    "# https://spacy.io/api/token#children\n",
    "text = \"Jammingbot is a fantasy on the theme of a post-apocalyptic future, when the main functions of the Internet and assistant bots will be defeated and only one self-replicating bot will remain, aimlessly plowing the Internet. This is a bot that has no goal, but only a path.\"\n",
    "            \n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# print(text)\n",
    "# cleaned_tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "# cleaned_tokens = [token.lemma_ for token in doc if not token.is_punct]\n",
    "# clean_text = \" \".join(cleaned_tokens)\n",
    "# print(clean_text)\n",
    "# doc = nlp(clean_text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text}>{token.head}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)\n",
    "displacy.serve(doc, style=\"dep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Ищем токен \"Jamming bot\"\n",
    "query_token = None\n",
    "for token in doc:\n",
    "    if token.text.lower() == \"jammingbot\":\n",
    "        query_token = token\n",
    "\n",
    "if query_token:\n",
    "    print(f\"Найден токен '{query_token.text} {query_token.nbor(1).text}'\")\n",
    "\n",
    "    # Слова, связанные с \"Jamming bot\"\n",
    "    print(\"\\nСлова, связанные с 'Jamming bot', и типы зависимостей:\")\n",
    "    for child in query_token.children:\n",
    "        print(f\"{child.text} ({child.dep_})\")\n",
    "\n",
    "    # Родитель \"Jamming bot\"\n",
    "    print(f\"\\nРодитель 'Jammingbot': {query_token.head.text} ({query_token.head.dep_})\")\n",
    "\n",
    "    # Полное предложение\n",
    "    print(\"\\nПредложение:\")\n",
    "    print(query_token.sent)\n",
    "else:\n",
    "    print(\"'Jamming bot' не найдено в тексте.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)\n",
    "keywords = [token.text.lower() for token in doc if token.pos_ in [\"NOUN\", \"ADJ\"] and not token.is_stop]\n",
    "keyword_counts = Counter(keywords)\n",
    "\n",
    "print(\"Top-5 Keywords:\")\n",
    "print(keyword_counts.most_common(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "doc = nlp(text)\n",
    "query = nlp(\"bot\")\n",
    "similarities = {}\n",
    "for token in doc:\n",
    "    if token.has_vector and query.has_vector:\n",
    "        similarity = query.similarity(token)\n",
    "        if similarity > 0:  # Фильтрация значений, близких к нулю\n",
    "            similarities[token.text] = similarity\n",
    "\n",
    "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Similarity w '{query.text}':\")\n",
    "for word, similarity in sorted_similarities[0:30]:\n",
    "    print(f\"{word}: {similarity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
